{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as path_effects\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = datasets.MNIST(root='./data', train=True, \n",
    "                               transform=None, target_transform=None, download=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', train=True, \n",
    "                               transform=None, target_transform=None, download=False)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, \n",
    "                               transform=None, target_transform=None, download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = {}\n",
    "for i in range(10):\n",
    "    class_counts[i] = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_dataset):\n",
    "    class_counts[int(target)].append(batch_idx)\n",
    "    \n",
    "subset_indices_train = np.array([], dtype='int8')\n",
    "subset_indices_valid = np.array([], dtype='int8')\n",
    "\n",
    "np.random.seed(0)\n",
    "for c in class_counts:\n",
    "    t_size = int(len(class_counts[c])*0.85)\n",
    "    t = np.random.choice(class_counts[c], size=t_size)\n",
    "    v = []\n",
    "    for i in range(len(class_counts[c])):\n",
    "        if i not in t:\n",
    "            v.append(int(i))\n",
    "    \n",
    "    subset_indices_train = np.concatenate((subset_indices_train, t), axis=None)\n",
    "    subset_indices_valid = np.concatenate((subset_indices_valid, v), axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('./data', train=True, download=False,\n",
    "            transform=transforms.Compose([       # Data preprocessing\n",
    "                transforms.ToTensor(),           # Add data augmentation here\n",
    "                transforms.Normalize((0.1307,), (0.3081,))\n",
    "            ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(subset_indices_train)\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size,\n",
    "    sampler=SubsetRandomSampler(subset_indices_valid)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load My Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyConvNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5), stride=1, padding=2, padding_mode = 'reflect')\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(5,5), stride=1, padding=2, padding_mode = 'reflect')\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3), stride=1, padding=2, padding_mode = 'reflect')\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=(3,3), stride=1, padding=2, padding_mode = 'reflect')\n",
    "        \n",
    "        self.dropout1 = nn.Dropout2d(0.5)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(128, 96)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=96)\n",
    "        self.fc2 = nn.Linear(96, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 4)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.avg_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_model = MyConvNet()\n",
    "aug_model.load_state_dict(torch.load(\"mnist_model4_aug.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present at least 9 examples from the test set where your classifier made a mistake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, test_loader, subset_indices_valid):\n",
    "incorrect_images = []\n",
    "true_incorrect_labels = []\n",
    "pred_incorrect_labels = []\n",
    "\n",
    "incorrect_count = 0\n",
    "correct_count = 0\n",
    "\n",
    "\n",
    "aug_model.eval()    # Set the model to inference mode\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "    for data, target in test_loader:\n",
    "        data, target = data, target\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        for p in range(len(pred)):\n",
    "            if pred[p] != target[p]:\n",
    "                incorrect_count += 1\n",
    "                incorrect_images.append(data[p])\n",
    "                true_incorrect_labels.append(target[p])\n",
    "                pred_incorrect_labels.append(pred[p])\n",
    "            else:\n",
    "                correct_count += 1\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "total = len(subset_indices_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect_images = []\n",
    "print(incorrect_count)\n",
    "print(correct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    img = incorrect_images[i]\n",
    "    plt.imshow(img[0, :, :])\n",
    "    plt.title(\"True = \"+str(true_incorrect_labels[i].item()) +\n",
    "             \", Predicted = \"+str(pred_incorrect_labels[i].item()))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize at least 9 of the learned kernels from the first layer of your network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_weights = aug_model.conv1.weight.data\n",
    "conv2_weights = aug_model.conv2.weight.data\n",
    "conv3_weights = aug_model.conv3.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_display = []\n",
    "for i in range(10):\n",
    "    kernel_conv1 = conv1_weights[i,0,:,:]\n",
    "    kernel_display.append(kernel_conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 10):\n",
    "    img = kernel_display[i]\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Kernel of First Conv Layer\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Confusion Matrix for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(np.array(Y_test), np.array(Y_pred), normalize=None)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Normalized Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, class_names, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your network to convert each image in the test set into a feature vector (taken from just before the final linear layer). Visualize this high-dimensional embedding in 2D using tSNE (each class should have its own color)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_process(model, x):\n",
    "#     print(x.shape)\n",
    "    x = model.conv1(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = model.dropout1(x)\n",
    "#         print(x.shape)\n",
    "\n",
    "    x = model.conv2(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 4)\n",
    "    x = model.dropout2(x)\n",
    "#         print(x.shape)\n",
    "#         print(x)\n",
    "\n",
    "    x = model.conv3(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.avg_pool2d(x, 2)\n",
    "    x = model.dropout2(x)\n",
    "#         print(x.shape)\n",
    "\n",
    "    x = model.conv4(x)\n",
    "    x = F.relu(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x = model.dropout2(x)\n",
    "#         print(x.shape)\n",
    "\n",
    "    x = torch.flatten(x, 1)\n",
    "#         print(x.shape)\n",
    "    x = model.fc1(x)\n",
    "    x = model.bn1(x)\n",
    "\n",
    "    x = F.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, test_loader, subset_indices_valid):\n",
    "embedding_info = []\n",
    "targets = []\n",
    "\n",
    "\n",
    "aug_model.eval()    # Set the model to inference mode\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():   # For the inference step, gradient is not computed\n",
    "    for data, target in test_loader:\n",
    "        data, target = data, target\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "#         print(data.shape)\n",
    "#         print(len(pred))\n",
    "\n",
    "        emb = forward_process(aug_model, data)\n",
    "        embedding_info.append(emb)\n",
    "        targets.append(target[0])\n",
    "        \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "total = len(subset_indices_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_info2 = torch.cat(embedding_info, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tsne = TSNE(random_state=123).fit_transform(embedding_info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = test_tsne.fit_transform(embedding_info2)\n",
    "Y = test_tsne\n",
    "# ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], s=0.1, cmap='viridis', c='r')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_tsne\n",
    "colors = np.array(targets)\n",
    "\n",
    "num_classes = len(np.unique(colors))\n",
    "palette = np.array(sns.color_palette(\"hls\", num_classes))\n",
    "\n",
    "# create a scatter plot.\n",
    "f = plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter(x[:,0], x[:,1], lw=0, s=40, c=palette[colors.astype(np.int)])\n",
    "plt.xlim(-25, 25)\n",
    "plt.ylim(-25, 25)\n",
    "ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "# add the labels for each digit corresponding to the label\n",
    "txts = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "\n",
    "    # Position of each label at median of data points.\n",
    "    print(x[colors == i, :].shape)\n",
    "    xtext, ytext = np.median(x[colors == i, :], axis=0)\n",
    "    txt = ax.text(xtext, ytext, str(i), fontsize=24)\n",
    "    txt.set_path_effects([\n",
    "        path_effects.Stroke(linewidth=5, foreground=\"w\"),\n",
    "        path_effects.Normal()])\n",
    "    txts.append(txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose one image I0 with feature vector x0 from the test set. Find the 8 images I1, I2, …, I8 in the test set whose feature vectors are closest in Euclidean distance to x0. Repeat this process for at least 3 more choices of I0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean(x, y):\n",
    "    distance = 0\n",
    "    for i in range(len(x)):\n",
    "        distance += ((x[i]-y[i])**2)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0_choices = []\n",
    "image0_targets = []\n",
    "for data, target in test_loader:\n",
    "    data, target = data, target\n",
    "    image0_choices.append(data)\n",
    "    image0_targets.append(target[0])\n",
    "    if len(image0_choices) ==3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(image0_choices)):\n",
    "emb_img0 = embedding_info[0][0]\n",
    "\n",
    "distances = []\n",
    "for j in range(len(embedding_info)):\n",
    "#     if i == j:\n",
    "#         continue\n",
    "    check_emb = embedding_info[j][0]\n",
    "    dist = euclidean(emb_img0, check_emb)\n",
    "    distances.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "distances_to_img0 = np.array(distances)\n",
    "idx = np.argsort(distances_to_img0)[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_images_all[0][0,:,:])\n",
    "plt.show()\n",
    "\n",
    "for index in idx[1:]:\n",
    "    plt.imshow(test_images_all[index][0,:,:])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(image0_choices)):\n",
    "emb_img0 = embedding_info[1][0]\n",
    "\n",
    "distances = []\n",
    "for j in range(len(embedding_info)):\n",
    "#     if i == j:\n",
    "#         continue\n",
    "    check_emb = embedding_info[j][0]\n",
    "    dist = euclidean(emb_img0, check_emb)\n",
    "    distances.append(dist)\n",
    "    \n",
    "k = 10\n",
    "distances_to_img0 = np.array(distances)\n",
    "idx = np.argsort(distances_to_img0)[:k]\n",
    "plt.imshow(test_images_all[1][0,:,:])\n",
    "plt.show()\n",
    "\n",
    "for index in idx[2:]:\n",
    "    plt.imshow(test_images_all[index][0,:,:])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(image0_choices)):\n",
    "emb_img0 = embedding_info[2][0]\n",
    "\n",
    "distances = []\n",
    "for j in range(len(embedding_info)):\n",
    "#     if i == j:\n",
    "#         continue\n",
    "    check_emb = embedding_info[j][0]\n",
    "    dist = euclidean(emb_img0, check_emb)\n",
    "    distances.append(dist)\n",
    "    \n",
    "k = 11\n",
    "distances_to_img0 = np.array(distances)\n",
    "idx = np.argsort(distances_to_img0)[:k]\n",
    "plt.imshow(test_images_all[2][0,:,:])\n",
    "plt.show()\n",
    "\n",
    "for index in idx[3:]:\n",
    "    plt.imshow(test_images_all[index][0,:,:])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(image0_choices)):\n",
    "emb_img0 = embedding_info[3][0]\n",
    "\n",
    "distances = []\n",
    "for j in range(len(embedding_info)):\n",
    "#     if i == j:\n",
    "#         continue\n",
    "    check_emb = embedding_info[j][0]\n",
    "    dist = euclidean(emb_img0, check_emb)\n",
    "    distances.append(dist)\n",
    "    \n",
    "k = 12\n",
    "distances_to_img0 = np.array(distances)\n",
    "idx = np.argsort(distances_to_img0)[:k]\n",
    "plt.imshow(test_images_all[3][0,:,:])\n",
    "plt.show()\n",
    "\n",
    "for index in idx[4:]:\n",
    "    plt.imshow(test_images_all[index][0,:,:])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
